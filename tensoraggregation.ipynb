{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEUOU3dfAAJySDMNDogpwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jevylux/pytorchtraining/blob/main/tensoraggregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvjEUhsy8U5K",
        "outputId": "169edd5b-64dd-4c34-d104-295c8453e29b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXStK5u57dxn",
        "outputId": "e72c1797-4b7f-460f-9016-069ad98a12ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "torch.int64\n",
            "tensor(0)\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#finding the min, max, mean, sum etc ( tensor aggregation)\n",
        "x = torch.arange(0,100,10)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "# find the min\n",
        "print(torch.min(x))\n",
        "print(x.min())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the max\n",
        "print(torch.max(x))\n",
        "print(x.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgGWdsUk8Wzj",
        "outputId": "bde3c695-ab5d-4fc4-f44b-a900a30f133b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(90)\n",
            "tensor(90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find mean.  -> returns an error because it is an integer\n",
        "print(torch.mean(x))\n",
        "print(x.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "Sf-BP4zG8nof",
        "outputId": "3f02d3ef-aa06-4147-f197-af90ddc3355d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f269e6c4d725>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#find mean.  -> returns an error because it is an integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to change the datatype\n",
        "print(torch.mean(x.type(torch.float32)))\n",
        "print(x.type(torch.float32).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwKWBKmY9SOS",
        "outputId": "a31af32b-3234-4cb7-8fb0-2dbb2c87d267"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45.)\n",
            "tensor(45.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the sum\n",
        "print(torch.sum(x))\n",
        "print(x.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITPhxM0b952u",
        "outputId": "5302facc-4e21-4717-902d-1b2a2807663d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(450)\n",
            "tensor(450)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the positional min and max - returns the index of tensor where the min or max occured\n",
        "print(x.argmin())\n",
        "print(x.argmax())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd1lRENI-Pc8",
        "outputId": "43a41223-f0d2-4238-c6e0-195270074432"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n",
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping, stacking, squeezing and unsqueezing tensors\n",
        "# reshaping - reshaps an input tensor to a defined shape\n",
        "# View - return a view of an input tensor of certain shape but keep the same memory as original tensor\n",
        "# stacking - combine multile tensor on each other ( vertical stacks, horizontal stack)\n",
        "# squeeze - removes all '1' dimensions from a tensor\n",
        "# unsqueeze - add a '1' dimension to a target tensor\n",
        "# permute - return a view of the input with dimensions permuted(sdwapped) in a certain way\n",
        "\n",
        "x = torch.arange(1.,11.)\n",
        "print(x, \" - \", x.shape)\n",
        "\n",
        "# add an  extra dimension - reshape has to be comptaible with the original shape\n",
        "x_reshaped = x.reshape(1, 10)\n",
        "print(x_reshaped, \" - \", x_reshaped.shape)\n",
        "\n",
        "x_reshaped = x.reshape(10, 1)\n",
        "print(x_reshaped, \" - \", x_reshaped.shape)\n",
        "\n",
        "x_reshaped = x.reshape(5, 2)\n",
        "print(x_reshaped, \" - \", x_reshaped.shape)\n",
        "\n",
        "x_reshaped = x.reshape(2, 5)\n",
        "print(x_reshaped, \" - \", x_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOljcmJv_ckv",
        "outputId": "750d377f-ff8f-4fdb-c493-6adb2fda8fc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])  -  torch.Size([10])\n",
            "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])  -  torch.Size([1, 10])\n",
            "tensor([[ 1.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.],\n",
            "        [ 5.],\n",
            "        [ 6.],\n",
            "        [ 7.],\n",
            "        [ 8.],\n",
            "        [ 9.],\n",
            "        [10.]])  -  torch.Size([10, 1])\n",
            "tensor([[ 1.,  2.],\n",
            "        [ 3.,  4.],\n",
            "        [ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])  -  torch.Size([5, 2])\n",
            "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.,  9., 10.]])  -  torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the view\n",
        "z = x.view(1,10)\n",
        "print(z, \" - \", z.shape)\n",
        "\n",
        "# z is a fifferent view of x, they share the same memory\n",
        "# thus changing z changes x\n",
        "z[:,0] = 5\n",
        "print(x)\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJouEqwBbW3",
        "outputId": "68fe0a50-d286-44a5-9776-1815596f6817"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])  -  torch.Size([1, 10])\n",
            "tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
            "tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import X_OK\n",
        "# stack tensors on top of eachn other\n",
        "x_stacked = torch.stack([x,x,x],dim=0)\n",
        "print(x_stacked, x_stacked.shape)\n",
        "x_stacked = torch.stack([x,x,x],dim=1)\n",
        "print(x_stacked, x_stacked.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rpWSHrgDS2R",
        "outputId": "d89eb237-f376-4576-aeac-0f220f66535a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
            "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
            "        [ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]) torch.Size([3, 10])\n",
            "tensor([[ 5.,  5.,  5.],\n",
            "        [ 2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.],\n",
            "        [ 9.,  9.,  9.],\n",
            "        [10., 10., 10.]]) torch.Size([10, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squeeze takes away an extra dimensions\n",
        "x_reshaped = x.reshape(1,10)\n",
        "print(f\"Previous tensor : {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "# see the double [[ in the result ?\n",
        "# squeeze will remove it\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"new tensor : {x_squeezed }\")\n",
        "print(f\"fnew shape: {x_squeezed .shape}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79343rhpEcat",
        "outputId": "eb550bc1-8f69-4978-926a-ce4ecca4aa11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor : tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
            "Previous shape: torch.Size([1, 10])\n",
            "new tensor : tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
            "fnew shape: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueeze adds a single dimension to a target tensor at a specific dim ( dimension)\n",
        "print(f\"Previous target {x_squeezed}\")\n",
        "print(f\"Previous shape {x_squeezed.shape}\")\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "\n",
        "print(f\"new tensor dim=0: {x_unsqueezed }\")\n",
        "print(f\"fnew shape: {x_unsqueezed .shape}\")\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "\n",
        "print(f\"new tensor dim=1: {x_unsqueezed }\")\n",
        "print(f\"fnew shape: {x_unsqueezed .shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDN5sVC6HMwB",
        "outputId": "f160d794-8b13-4c79-bbc9-44ef5cae7d82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous target tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
            "Previous shape torch.Size([10])\n",
            "new tensor dim=0: tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
            "fnew shape: torch.Size([1, 10])\n",
            "new tensor dim=1: tensor([[ 5.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.],\n",
            "        [ 5.],\n",
            "        [ 6.],\n",
            "        [ 7.],\n",
            "        [ 8.],\n",
            "        [ 9.],\n",
            "        [10.]])\n",
            "fnew shape: torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute -> reaarange the dimension\n",
        "x_original = torch.rand(size=(10,12,3))  # [height, width, color_channel]\n",
        "print(x_original)\n",
        "print(x_original.size())\n",
        "print(x_original.shape)\n",
        "# permute the original tensor to rearrange the axis ( or dimension) order to [color_channel, height, width]\n",
        "x_permuted = torch.permute(x_original,(2,0,1))\n",
        "print(x_permuted)\n",
        "print(x_permuted.size())\n",
        "print(x_permuted.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3jZnVbRJI_Q",
        "outputId": "7bad14fa-4223-4484-9b48-e04041b93892"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6481, 0.5261, 0.7459],\n",
            "         [0.3144, 0.7714, 0.7463],\n",
            "         [0.5077, 0.8575, 0.4503],\n",
            "         [0.9891, 0.3402, 0.9960],\n",
            "         [0.4715, 0.4617, 0.5685],\n",
            "         [0.1590, 0.1127, 0.8310],\n",
            "         [0.9958, 0.7920, 0.5943],\n",
            "         [0.9995, 0.4285, 0.1050],\n",
            "         [0.7109, 0.0192, 0.6181],\n",
            "         [0.1203, 0.4045, 0.2559],\n",
            "         [0.6470, 0.0089, 0.3907],\n",
            "         [0.0382, 0.9292, 0.4074]],\n",
            "\n",
            "        [[0.0030, 0.8643, 0.6417],\n",
            "         [0.8388, 0.9481, 0.7728],\n",
            "         [0.7237, 0.6066, 0.7916],\n",
            "         [0.8355, 0.7341, 0.9885],\n",
            "         [0.7620, 0.3231, 0.2192],\n",
            "         [0.9992, 0.5028, 0.5127],\n",
            "         [0.2283, 0.4660, 0.8237],\n",
            "         [0.6819, 0.5230, 0.1902],\n",
            "         [0.3533, 0.2671, 0.1352],\n",
            "         [0.6165, 0.7430, 0.2490],\n",
            "         [0.9693, 0.5456, 0.6796],\n",
            "         [0.2438, 0.1192, 0.2596]],\n",
            "\n",
            "        [[0.3638, 0.2839, 0.8851],\n",
            "         [0.4776, 0.1371, 0.5440],\n",
            "         [0.9308, 0.6875, 0.3420],\n",
            "         [0.1390, 0.3065, 0.8510],\n",
            "         [0.8265, 0.2008, 0.7702],\n",
            "         [0.1831, 0.7002, 0.9387],\n",
            "         [0.3675, 0.9129, 0.5000],\n",
            "         [0.4059, 0.2810, 0.5298],\n",
            "         [0.3542, 0.1978, 0.7005],\n",
            "         [0.7305, 0.5016, 0.0781],\n",
            "         [0.0369, 0.6827, 0.8191],\n",
            "         [0.1069, 0.5092, 0.3264]],\n",
            "\n",
            "        [[0.7389, 0.6811, 0.8625],\n",
            "         [0.3098, 0.9212, 0.8698],\n",
            "         [0.0727, 0.9270, 0.6749],\n",
            "         [0.6861, 0.3621, 0.4538],\n",
            "         [0.6043, 0.5638, 0.5086],\n",
            "         [0.2382, 0.7207, 0.9041],\n",
            "         [0.2906, 0.2900, 0.7234],\n",
            "         [0.3790, 0.9978, 0.4032],\n",
            "         [0.8231, 0.6070, 0.6543],\n",
            "         [0.0034, 0.0713, 0.5512],\n",
            "         [0.8983, 0.3970, 0.5778],\n",
            "         [0.2967, 0.4213, 0.0242]],\n",
            "\n",
            "        [[0.4616, 0.5571, 0.5908],\n",
            "         [0.0317, 0.3933, 0.1712],\n",
            "         [0.5755, 0.9265, 0.4797],\n",
            "         [0.8128, 0.2289, 0.7709],\n",
            "         [0.3762, 0.8402, 0.2744],\n",
            "         [0.7797, 0.7959, 0.5015],\n",
            "         [0.5223, 0.8222, 0.4080],\n",
            "         [0.5727, 0.9540, 0.0247],\n",
            "         [0.0250, 0.5307, 0.0508],\n",
            "         [0.8378, 0.0609, 0.3201],\n",
            "         [0.6958, 0.9715, 0.5570],\n",
            "         [0.2765, 0.0468, 0.5499]],\n",
            "\n",
            "        [[0.1017, 0.7396, 0.9180],\n",
            "         [0.5332, 0.2143, 0.2885],\n",
            "         [0.5831, 0.2610, 0.4519],\n",
            "         [0.7609, 0.6799, 0.2862],\n",
            "         [0.9336, 0.1087, 0.7095],\n",
            "         [0.1134, 0.2034, 0.8160],\n",
            "         [0.4343, 0.3361, 0.8732],\n",
            "         [0.0656, 0.2220, 0.1321],\n",
            "         [0.5389, 0.6222, 0.5684],\n",
            "         [0.3336, 0.4334, 0.9691],\n",
            "         [0.9254, 0.5939, 0.8479],\n",
            "         [0.5066, 0.5686, 0.0579]],\n",
            "\n",
            "        [[0.2788, 0.9506, 0.8406],\n",
            "         [0.6150, 0.8304, 0.3437],\n",
            "         [0.2750, 0.0617, 0.2721],\n",
            "         [0.5396, 0.9450, 0.5362],\n",
            "         [0.3203, 0.9148, 0.2862],\n",
            "         [0.9546, 0.9317, 0.2077],\n",
            "         [0.8904, 0.1937, 0.3507],\n",
            "         [0.4519, 0.7400, 0.3186],\n",
            "         [0.4401, 0.2912, 0.5335],\n",
            "         [0.0567, 0.0800, 0.3193],\n",
            "         [0.6684, 0.6128, 0.5115],\n",
            "         [0.7954, 0.4193, 0.0994]],\n",
            "\n",
            "        [[0.2427, 0.7226, 0.2362],\n",
            "         [0.6764, 0.3993, 0.0775],\n",
            "         [0.3650, 0.6701, 0.8119],\n",
            "         [0.6320, 0.2930, 0.6803],\n",
            "         [0.2136, 0.1158, 0.1811],\n",
            "         [0.1546, 0.6000, 0.9900],\n",
            "         [0.0359, 0.8617, 0.7499],\n",
            "         [0.5914, 0.4100, 0.5145],\n",
            "         [0.3861, 0.0596, 0.8138],\n",
            "         [0.7665, 0.8484, 0.3885],\n",
            "         [0.0891, 0.0389, 0.0613],\n",
            "         [0.7360, 0.8541, 0.3068]],\n",
            "\n",
            "        [[0.2585, 0.6761, 0.5283],\n",
            "         [0.4034, 0.7036, 0.8132],\n",
            "         [0.0421, 0.2032, 0.4086],\n",
            "         [0.5323, 0.0818, 0.3472],\n",
            "         [0.1946, 0.0029, 0.1743],\n",
            "         [0.0564, 0.2047, 0.3134],\n",
            "         [0.9829, 0.2175, 0.2888],\n",
            "         [0.8190, 0.4844, 0.8340],\n",
            "         [0.6159, 0.4250, 0.6370],\n",
            "         [0.3929, 0.8536, 0.0706],\n",
            "         [0.1260, 0.3769, 0.5752],\n",
            "         [0.6685, 0.3750, 0.1132]],\n",
            "\n",
            "        [[0.4355, 0.2030, 0.0519],\n",
            "         [0.3082, 0.6664, 0.4629],\n",
            "         [0.0053, 0.4897, 0.6700],\n",
            "         [0.1987, 0.3372, 0.1675],\n",
            "         [0.4133, 0.6631, 0.6902],\n",
            "         [0.6788, 0.8881, 0.4822],\n",
            "         [0.7057, 0.2981, 0.5477],\n",
            "         [0.2413, 0.1061, 0.0046],\n",
            "         [0.2043, 0.8228, 0.9212],\n",
            "         [0.9052, 0.8729, 0.4723],\n",
            "         [0.8398, 0.2388, 0.3243],\n",
            "         [0.5123, 0.9897, 0.9825]]])\n",
            "torch.Size([10, 12, 3])\n",
            "torch.Size([10, 12, 3])\n",
            "tensor([[[0.6481, 0.3144, 0.5077, 0.9891, 0.4715, 0.1590, 0.9958, 0.9995,\n",
            "          0.7109, 0.1203, 0.6470, 0.0382],\n",
            "         [0.0030, 0.8388, 0.7237, 0.8355, 0.7620, 0.9992, 0.2283, 0.6819,\n",
            "          0.3533, 0.6165, 0.9693, 0.2438],\n",
            "         [0.3638, 0.4776, 0.9308, 0.1390, 0.8265, 0.1831, 0.3675, 0.4059,\n",
            "          0.3542, 0.7305, 0.0369, 0.1069],\n",
            "         [0.7389, 0.3098, 0.0727, 0.6861, 0.6043, 0.2382, 0.2906, 0.3790,\n",
            "          0.8231, 0.0034, 0.8983, 0.2967],\n",
            "         [0.4616, 0.0317, 0.5755, 0.8128, 0.3762, 0.7797, 0.5223, 0.5727,\n",
            "          0.0250, 0.8378, 0.6958, 0.2765],\n",
            "         [0.1017, 0.5332, 0.5831, 0.7609, 0.9336, 0.1134, 0.4343, 0.0656,\n",
            "          0.5389, 0.3336, 0.9254, 0.5066],\n",
            "         [0.2788, 0.6150, 0.2750, 0.5396, 0.3203, 0.9546, 0.8904, 0.4519,\n",
            "          0.4401, 0.0567, 0.6684, 0.7954],\n",
            "         [0.2427, 0.6764, 0.3650, 0.6320, 0.2136, 0.1546, 0.0359, 0.5914,\n",
            "          0.3861, 0.7665, 0.0891, 0.7360],\n",
            "         [0.2585, 0.4034, 0.0421, 0.5323, 0.1946, 0.0564, 0.9829, 0.8190,\n",
            "          0.6159, 0.3929, 0.1260, 0.6685],\n",
            "         [0.4355, 0.3082, 0.0053, 0.1987, 0.4133, 0.6788, 0.7057, 0.2413,\n",
            "          0.2043, 0.9052, 0.8398, 0.5123]],\n",
            "\n",
            "        [[0.5261, 0.7714, 0.8575, 0.3402, 0.4617, 0.1127, 0.7920, 0.4285,\n",
            "          0.0192, 0.4045, 0.0089, 0.9292],\n",
            "         [0.8643, 0.9481, 0.6066, 0.7341, 0.3231, 0.5028, 0.4660, 0.5230,\n",
            "          0.2671, 0.7430, 0.5456, 0.1192],\n",
            "         [0.2839, 0.1371, 0.6875, 0.3065, 0.2008, 0.7002, 0.9129, 0.2810,\n",
            "          0.1978, 0.5016, 0.6827, 0.5092],\n",
            "         [0.6811, 0.9212, 0.9270, 0.3621, 0.5638, 0.7207, 0.2900, 0.9978,\n",
            "          0.6070, 0.0713, 0.3970, 0.4213],\n",
            "         [0.5571, 0.3933, 0.9265, 0.2289, 0.8402, 0.7959, 0.8222, 0.9540,\n",
            "          0.5307, 0.0609, 0.9715, 0.0468],\n",
            "         [0.7396, 0.2143, 0.2610, 0.6799, 0.1087, 0.2034, 0.3361, 0.2220,\n",
            "          0.6222, 0.4334, 0.5939, 0.5686],\n",
            "         [0.9506, 0.8304, 0.0617, 0.9450, 0.9148, 0.9317, 0.1937, 0.7400,\n",
            "          0.2912, 0.0800, 0.6128, 0.4193],\n",
            "         [0.7226, 0.3993, 0.6701, 0.2930, 0.1158, 0.6000, 0.8617, 0.4100,\n",
            "          0.0596, 0.8484, 0.0389, 0.8541],\n",
            "         [0.6761, 0.7036, 0.2032, 0.0818, 0.0029, 0.2047, 0.2175, 0.4844,\n",
            "          0.4250, 0.8536, 0.3769, 0.3750],\n",
            "         [0.2030, 0.6664, 0.4897, 0.3372, 0.6631, 0.8881, 0.2981, 0.1061,\n",
            "          0.8228, 0.8729, 0.2388, 0.9897]],\n",
            "\n",
            "        [[0.7459, 0.7463, 0.4503, 0.9960, 0.5685, 0.8310, 0.5943, 0.1050,\n",
            "          0.6181, 0.2559, 0.3907, 0.4074],\n",
            "         [0.6417, 0.7728, 0.7916, 0.9885, 0.2192, 0.5127, 0.8237, 0.1902,\n",
            "          0.1352, 0.2490, 0.6796, 0.2596],\n",
            "         [0.8851, 0.5440, 0.3420, 0.8510, 0.7702, 0.9387, 0.5000, 0.5298,\n",
            "          0.7005, 0.0781, 0.8191, 0.3264],\n",
            "         [0.8625, 0.8698, 0.6749, 0.4538, 0.5086, 0.9041, 0.7234, 0.4032,\n",
            "          0.6543, 0.5512, 0.5778, 0.0242],\n",
            "         [0.5908, 0.1712, 0.4797, 0.7709, 0.2744, 0.5015, 0.4080, 0.0247,\n",
            "          0.0508, 0.3201, 0.5570, 0.5499],\n",
            "         [0.9180, 0.2885, 0.4519, 0.2862, 0.7095, 0.8160, 0.8732, 0.1321,\n",
            "          0.5684, 0.9691, 0.8479, 0.0579],\n",
            "         [0.8406, 0.3437, 0.2721, 0.5362, 0.2862, 0.2077, 0.3507, 0.3186,\n",
            "          0.5335, 0.3193, 0.5115, 0.0994],\n",
            "         [0.2362, 0.0775, 0.8119, 0.6803, 0.1811, 0.9900, 0.7499, 0.5145,\n",
            "          0.8138, 0.3885, 0.0613, 0.3068],\n",
            "         [0.5283, 0.8132, 0.4086, 0.3472, 0.1743, 0.3134, 0.2888, 0.8340,\n",
            "          0.6370, 0.0706, 0.5752, 0.1132],\n",
            "         [0.0519, 0.4629, 0.6700, 0.1675, 0.6902, 0.4822, 0.5477, 0.0046,\n",
            "          0.9212, 0.4723, 0.3243, 0.9825]]])\n",
            "torch.Size([3, 10, 12])\n",
            "torch.Size([3, 10, 12])\n"
          ]
        }
      ]
    }
  ]
}